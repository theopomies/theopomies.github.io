---
title: Writing triton kernels with Daniel Han from Unsloth + linear algebra
description: A guest speaker session with Daniel Han on writig triton kernel (S2S), a light mode to this website and new linear algebra notes
categories: [mle, math]
date: 2025-09-11
---

### Linear algebra notes

Today I wrote some more linear algebra notes, on [linear dependence](/notes/linear-algebra.qmd#sec-linear-dependence), [rank](/notes/linear-algebra.qmd#sec-rank), [basis](/notes/linear-algebra.qmd#sec-basis) and [dimension](/notes/linear-algebra.qmd#sec-dimension). In the process I also wrote about [vector spaces](/notes/linear-algebra.qmd#sec-vector-space). I really begin to feel the value of these notes, both as an external memory to refer to later, but also as a learning process allowing me to really understand to summarize and re-explain.

### Daniel Han

As part of S2S we had a guest lecture by [Daniel Han](https://x.com/danielhanchen){target=_blank} from [Unsloth](https://unsloth.ai){target=_blank} on [Triton](https://triton-lang.org/main/index.html){target=_blank} and custom kernels. It was super interesting because it was working from first principles, and that's the way I work. Instead of diving into triton's DSL etc, he took a pen and a stack of paper and wrote neural network graphs of computations, deriving them by hand and explaining how custom training kernels were written as a way to speed-up backprop by using derivation tricks, using our knowledge of calculus, caching computations and results to achieve a better result than a `torch.compile` or autograd.

### Light mode

I also took way too much time to get an OK-tier light mode for this website.
