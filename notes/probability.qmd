---
title: Probability and Information Theory
author: Theo POMIES
date: 2025-09-02
date-modified: 2025-09-16
description: Small Probability & Information Theory cheatsheet.
categories: [math]
---

```{python}
# | echo: false
import torch

# TODO: Add torch examples!
```

## Definitions & Formulas
### Outcomes and Events
When studying probability, we are performing experiments, random trials or observations. The set of all possible _outcomes_ of this experiment is $\mathcal{\Omega}$ (or $\mathcal{S}$). eg. When rolling a die, $\mathcal{\Omega} = \{1,2,3,4,5,6\}$.

We can group these outcomes into _events_ — $\mathcal{E} \subseteq \mathcal{\Omega}$. eg. The event $\mathcal{E} = \{$die shows an even number$\} = \{2, 4, 6\}$. Whenever the outcome $z$ of the random experiment satisfies $z \in \mathcal{E}$, the event $\mathcal{E}$ has occurred. Multiple events can occur from the same outcome, say we have $\mathcal{A} = \{3, 6\}$ "the result is divisible by 3" and $\mathcal{B} = \{2, 4, 6\}$. $z = 6$ satisfies both $\mathcal{A}$ and $\mathcal{B}$.

### Probability function

The **probability function** maps events onto a real value $P\colon \mathcal{E} \subseteq \mathcal{\Omega} \to [0, 1]$.

$\operatorname{P}(\mathcal{E})$ is the _probability associated with event $\mathcal{E}$_.

#### Properties

* $\operatorname{P}(\mathcal{E}) \geq 0$
* $\operatorname{P}(\mathcal{\Omega}) = 1, \operatorname{P}(\mathcal{\emptyset}) = 0$
* $\operatorname{P}(\mathcal{A} \cup \mathcal{B}) = \operatorname{P}(\mathcal{A}) + \operatorname{P}(\mathcal{B}) - \operatorname{P}(\mathcal{A} \cap \mathcal{B})$
* $\operatorname{P}(\bigcup_{i=1}^{\infty} \mathcal{A}_i) = \sum_{i=1}^{\infty} \operatorname{P}(\mathcal{A}_i), \quad \mathcal{A}_i \cap \mathcal{A}_j = \emptyset\: \text{for all}\: i \neq j$ (= if all events $\mathcal{A}_i$ are _mutually exclusive_)
* $\operatorname{P}(\mathcal{A} \cap \mathcal{B}) = \operatorname{P}(\mathcal{A} \mid \mathcal{B})\operatorname{P}(\mathcal{B})$
* $\operatorname{P}(\mathcal{A} \cap \mathcal{B}) = \operatorname{P}(\mathcal{A})\operatorname{P}(\mathcal{B}) \iff \mathcal{A} \perp \mathcal{B}$ (eg. 2 fair dice rolls)
* $\mathcal{A} \perp \mathcal{B} \iff \operatorname{P}(\mathcal{A} \mid \mathcal{B}) = \operatorname{P}(\mathcal{A})$

### Random Variables {#sec-random-variables}

A **random variable**  $X$ is a measurable function (mapping) $X \colon \mathcal{\Omega} \to \mathcal{E}$ from a sample space $\mathcal{\Omega}$ as a set of possible outcomes to a measurable space $\mathcal{E}$.

The probability that $X$ takes on a value in a measurable set $\mathcal{S} \in \mathcal{E}$ is written as
$$
\operatorname{P}(X \in \mathcal{S}) = \operatorname{P}(\{\omega \in \mathcal{\Omega} \mid X(\omega) \in \mathcal{S}\})
$$

The probability that $X$ takes a _discrete_ value $v$, denoted $X = v$, is $\operatorname{P}(X=v)$.

Expressions like $X = v$ or $X \geq v$ define **events**, i.e., subsets of $\Omega$ whose probability can be measured.

Random variables allow us to go from outcomes to values, like $X(\omega) = \omega$, the random variable that associates to each die its value (identity function). This is also an example of a _discrete_ random variable.

When $X$ is _continuous_, it doesn't make sense to have events like $X = v$ (and $\operatorname{P}(X = v) = 0$); rather we use $v \leq X \leq w$ and probability **densities**. An example would be the height of a population. Probabilities are described via a **probability density function** $p_X(x)$, with
$$
\operatorname{P}(v \le X \le w) = \int_v^w p_X(x)\,dx
$$

We denote the probability distribution of $X$ as $\operatorname{P}(X)$ (strictly speaking $P_X$, but we often write $P(X)$ for convenience).

:::{.callout-note}
When the measurable space $\mathcal{E}$ is multi-dimensional, like $\mathbb{R}^m$, we call the random variable $\mathbf{X} \in \mathbb{R}^m$ a **random vector**.
:::

#### Multiple Random Variables

$\operatorname{P}(A = a, B = b)$ is the **joint probability** of $A = a$ **and** $B = b$ (it's the intersection of the events $A = a$ and $B = b$). Equivalently it's $\operatorname{P}(\{A = a\} \cap \{B = b\})$, with an overloaded notation, the **joint probability distribution** becomes $\operatorname{P}(A, B)$

Obviously $$ \operatorname{P}(A = a, B = b) \leq \operatorname{P}(A=a) \quad \text{and} \quad \operatorname{P}(A = a, B = b) \leq \operatorname{P}(B=b) $$

Also, we can **marginalize** $$ \operatorname{P}(A = a) = \sum_v \operatorname{P}(A = a, B = v) $$

Because $A = a$ and $B = b$ are events,
$$\begin{aligned}
\operatorname{P}(A = a, B = b) & = \operatorname{P}(A = a \mid B = b)\operatorname{P}(B = b) \\
\iff \operatorname{P}(A = a \mid B = b) & = \operatorname{P}(A = a, B = b)/\operatorname{P}(B = b)
\end{aligned}$$

### Bayes' Theorem

From the properties and definitions above, we can derive the following formula

$$ \overbrace{\operatorname{P}(A \mid B)}^{\text{posterior probability}} = \dfrac{\overbrace{\operatorname{P}(B \mid A)}^{\text{likelihood}}\overbrace{\operatorname{P}(A)}^{\text{prior}}}{\underbrace{\operatorname{P}(B)}_{\text{observation}}} $$

* prior/hypothesis: our estimate or current belief about the probability of $A$
* observation/marginal likelihood/evidence: the evidence or observations we've made regarding $B$
* likelihood: a measure of how compatible our hypothesis is with our observation

A simplified version is $\operatorname{P}(A \mid B) \propto \operatorname{P}(B \mid A)\operatorname{P}(A)$

### Expectation

The **expectation** (or **expected value**) is the weighted average of the values of $X$.

Discrete case:

$$ \operatorname{E}[X] = \operatorname{E}_{X \sim P}[X] = \sum_x x\operatorname{P}(X=x) $$

Continuous case:

$$\operatorname{E}[X] = \int_{-\infty}^{\infty} x p(x) \;dx $$

To follow mathematical notation, sometimes we use $\mu$ to denote this average.

#### Properties

<!--- TODO --->

#### Expectation of a Random Vector

For a vector-valued random variable — ie. the **random vector** $\mathbf{X} \in \mathbb{R}^n$, we have $\mathbf{\mu} = \operatorname{E}_{\mathbf{X} \sim P}[\mathbf{X}]$ with $\mu_i = \operatorname{E}_{\mathbf{X} \sim P}[x_i]$ — the expectation of $\mathbf{X}$ is a vector of the expectations of each element $x_i$ of $\mathbf{X}$.

### Variance {#sec-variance}

The **variance** is a measure of dispersion, it quantifies _how much values deviate from their expectation, on average_.
The variance is the expectation of the squared difference between the values and the expected value.

$$ \operatorname{Var}(X) = \operatorname{E}[(X - \operatorname{E}[X])^2] = \operatorname{E}[X^2] - (\operatorname{E}[X])^2 $$

Because

$$ \operatorname{E}[X^2 - 2X\operatorname{E}[X] + \operatorname{E}[X]^2] = \operatorname{E}[X^2] - 2(\operatorname{E}[X])^2 + (\operatorname{E}[X])^2 $$

#### Variance of a Random Vector {#sec-var-random-vector}

For a random vector $\mathbf{X}$, we store the pairwise **variances** of elements and **[covariances @sec-covariance]** in a **[covariance matrix @sec-covariance-matrix]** (aka. auto-covariance matrix or variance matrix) noted $\mathbf{\Sigma}$ or $K_{\mathbf{x}\mathbf{x}}$ or $\operatorname{Cov}_{\mathbf{x} \sim P}$, defined as

$$ \mathbf{\Sigma} = \operatorname{E}_{\mathbf{X} \sim P}[(\mathbf{X} - \mathbf{\mu})(\mathbf{X} - \mathbf{\mu})^\top] $$
$$\begin{aligned}
\mathbf{\Sigma} = K_{\mathbf{X}\mathbf{Y}}
& = \operatorname{E}_{\mathbf{X} \sim P}[(\mathbf{X} - \mathbf{\mu})(\mathbf{X} - \mathbf{\mu})^\top] \\
& = \operatorname{E}[\mathbf{X}\mathbf{X}^\top] - \operatorname{E}[\mathbf{X}]\operatorname{E}[\mathbf{X}]^\top
\end{aligned}$$

:::{.callout-note}
Each entry $\Sigma_{i, j} = \operatorname{Cov}(X_i, X_j)$ — see [covariance @sec-covariance]), and by definition, for diagonal entries $\Sigma_{i, i} = \operatorname{Cov}(X_i, X_i) = \operatorname{Var}(X_i)$
:::

:::{.callout-note}
We have the following property when applying a linear transformation represented by the appropriately dimensioned matrix $\mathbf{A}$

$$
\begin{aligned}
\operatorname{Cov}(\mathbf{AX}, \mathbf{AX}) & = \operatorname{E}[(\mathbf{AX} - \operatorname{E}[\mathbf{AX}])(\mathbf{AX} - \operatorname{E}[\mathbf{AX}])^\top] \\
& = \operatorname{E}[\mathbf{AX}(\mathbf{AX})^\top] - \operatorname{E}[\mathbf{AX}]\operatorname{E}[(\mathbf{AX})^\top] \\
& = \operatorname{E}[\mathbf{AX}\mathbf{X}^\top\mathbf{A}^\top] - \operatorname{E}[\mathbf{AX}]\operatorname{E}[\mathbf{X}^\top\mathbf{A}^\top] \\
& = \mathbf{A}\operatorname{E}[\mathbf{X}\mathbf{X}^\top]\mathbf{A}^\top - \mathbf{A}\operatorname{E}[\mathbf{X}]\operatorname{E}[\mathbf{X}^\top]\mathbf{A}^\top \\
& = \mathbf{A}(\operatorname{E}[\mathbf{X}\mathbf{X}^\top] - \operatorname{E}[\mathbf{X}]\operatorname{E}[\mathbf{X}^\top])\mathbf{A}^\top \\
& = \mathbf{A}\mathbf{\Sigma}\mathbf{A}^\top
\end{aligned}
$$

<!---TODO--->
As a result of the [linearity of expectation]
:::

### Standard deviation

Because the [variance @sec-variance] is a squared difference, we can take its square root to get the **standard deviation** which has the benefit of being in the same unit as our random variable.

$$ \operatorname{Var}(X) = \sigma^2_X \iff \sigma_X = \sqrt{\operatorname{Var}(X)} $$

### Covariance {#sec-covariance}

**Covariance** is a measure of the joint variability of two [random variables @sec-random-variables].

$$ \operatorname{Cov}(X, Y) = \operatorname{E}[(X - \operatorname{E}[X])(Y - \operatorname{E}[Y])] $$

:::{.callout-note}
$\operatorname{Cov}(X, X) = \operatorname{E}[(X - \operatorname{E}[X])^2] = \operatorname{Var}(X)$
:::

#### Covariance Matrix of two Random Vectors {#sec-covariance-matrix}

For random vectors $\mathbf{X} \in \mathbb{R}^m$, $\mathbf{Y} \in \mathbb{R}^n$, the **covariance matrix** is a matrix $K_{\mathbf{X}\mathbf{Y}}$ defined as

$$\begin{aligned}
K_{\mathbf{X}\mathbf{Y}} & = \operatorname{E}[(\mathbf{X} - \operatorname{E}[\mathbf{X}])(\mathbf{Y} - \operatorname{E}[\mathbf{Y}])^\top] \\
& = \operatorname{E}[\mathbf{X}\mathbf{Y}^\top] - \operatorname{E}[\mathbf{X}]\operatorname{E}[\mathbf{Y}]^\top
\end{aligned}$$

We have $\operatorname{Cov}(X_i, Y_j) = K_{X_iY_j} = \operatorname{E}[(X_i - \operatorname{E}[X_i])(Y_j - \operatorname{E}[Y_j])]$ found at index $(i, j)$ in $K_{\mathbf{X}\mathbf{Y}}$

If $\mathbf{X} = \mathbf{Y}$ this is the [auto-covariance matrix or variance matrix @sec-var-random-vector] of this random vector $\mathbf{X}$

If $\mathbf{X} \neq \mathbf{Y}$ this is the **cross-covariance matrix** of $\mathbf{X}$ and $\mathbf{Y}$

<!--- TODO: correlation, KL-Divergence --->

## Proofs

Later!

## Notation

* $\mathcal{X}$: a set
* $\{a, b, c\}$: a set, with its elements
* $\emptyset$: the empty set
* $\mathcal{A} \subset \mathcal{B}$, $\mathcal{A} \subsetneq \mathcal{B}$: $\mathcal{A}$ is a proper/strict subset of $\mathcal{B}$
* $\mathcal{A} \subseteq \mathcal{B}$: $\mathcal{A}$ is a subest of $\mathcal{B}$
* $\mathcal{A} \cap \mathcal{B}$: the intersection of sets $\mathcal{A}$ and $\mathcal{B}$ — "$\mathcal{A}$ **and** $\mathcal{B}$"
* $\mathcal{A} \cup \mathcal{B}$: the union of sets $\mathcal{A}$ and $\mathcal{B}$ — "$\mathcal{A}$ **or** $\mathcal{B}$"
* $\mathcal{A} \setminus \mathcal{B}$: set subtraction of $\mathcal{B}$ from $\mathcal{A}$, elements from $\mathcal{A}$ but not in $\mathcal{B}$
* $\mathcal{S}$, $\mathcal{\Omega}$: the sample space / universe (the set of all possible outcomes)
* $|\mathcal{X}|$: the cardinality of set $\mathcal{X}$ (its number of events)
* $X$: a random variable
* $\mathbf{X}$: a random vector
* $P$: a probability distribution
* $X \sim P$: the random variable $X$ follows the probability distribution $P$
* $a \propto b$: $a$ is proportional to $b$, eg. $a = kb$
* $\operatorname{P}(\cdot)$: the probability function, maps events to their probability and random variables to their probability _distributions_
* $\operatorname{P}(X)$: depending on the context, a probability distribution _or_ the probability of any $X=x$, meaning the formula is true for any value
* $\operatorname{P}(X=x)$: the probability assigned to the event where random variable $X$ takes value $x$
* $\operatorname{P}(X \mid Y)$: the conditional probability distribution of $X$ given $Y$
* $\operatorname{p}(\cdot)$: a probability density function (PDF) associated with distribution $P$
* $\operatorname{E}[X]$: expectation of a random variable $X$
* $X \perp Y$: random variables $X$ and $Y$ are independent
* $X \perp Y \mid Z$: random variables  $X$  and  $Y$ are conditionally independent given $Z$
* $\sigma_X$: standard deviation of random variable $X$
* $\operatorname{Var}(X)$: variance of random variable $X$, equal to $\sigma^2_X$
* $\operatorname{Cov}(X, Y)$: covariance of random variables $X$ and $Y$
* $\operatorname{\rho}(X, Y)$: the Pearson correlation coefficient between $X$ and $Y$, equals $\frac{\operatorname{Cov}(X, Y)}{\sigma_X \sigma_Y}$
* $\operatorname{H}(X)$: entropy of random variable $X$
* $D_{\operatorname{KL}}(P\|Q)$: the KL-divergence (or relative entropy) from distribution $Q$ to distribution $P$
