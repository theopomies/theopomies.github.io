{
  "hash": "bef9d1109f14387028408d85c2863b09",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Probability and Information Theory\nauthor: Theo POMIES\ndate: 2025-09-02\ndate-modified: 2025-09-04\ndescription: Small Probability & Information Theory cheatsheet.\ncategories: [math]\n---\n\n\n\n## Definitions & Formulas\n### Outcomes and Events\nWhen studying probability, we are performing experiments, random trials or observations. The set of all possible _outcomes_ of this experiment is $\\mathcal{\\Omega}$ (or $\\mathcal{S}$). eg. When rolling a die, $\\mathcal{\\Omega} = \\{1,2,3,4,5,6\\}$.\n\nWe can group these outcomes into _events_ — $\\mathcal{E} \\subseteq \\mathcal{\\Omega}$. eg. The event $\\mathcal{E} = \\{$die shows an even number$\\} = \\{2, 4, 6\\}$. Whenever the outcome $z$ of the random experiment satisfies $z \\in \\mathcal{E}$, the event $\\mathcal{E}$ has occurred. Multiple events can occur from the same outcome, say we have $\\mathcal{A} = \\{3, 6\\}$ \"the result is divisible by 3\" and $\\mathcal{B} = \\{2, 4, 6\\}$. $z = 6$ satisfies both $\\mathcal{A}$ and $\\mathcal{B}$.\n\n### Probability function\n\nThe **probability function** maps events onto a real value $P\\colon \\mathcal{E} \\subseteq \\mathcal{\\Omega} \\to [0, 1]$.\n\n$\\operatorname{P}(\\mathcal{E})$ is the _probability associated with event $\\mathcal{E}$_.\n\n#### Properties\n\n* $\\operatorname{P}(\\mathcal{E}) \\geq 0$\n* $\\operatorname{P}(\\mathcal{\\Omega}) = 1, \\operatorname{P}(\\mathcal{\\emptyset}) = 0$\n* $\\operatorname{P}(\\mathcal{A} \\cup \\mathcal{B}) = \\operatorname{P}(\\mathcal{A}) + \\operatorname{P}(\\mathcal{B}) - \\operatorname{P}(\\mathcal{A} \\cap \\mathcal{B})$\n* $\\operatorname{P}(\\bigcup_{i=1}^{\\infty} \\mathcal{A}_i) = \\sum_{i=1}^{\\infty} \\operatorname{P}(\\mathcal{A}_i), \\quad \\mathcal{A}_i \\cap \\mathcal{A}_j = \\emptyset\\: \\text{for all}\\: i \\neq j$ (= if all events $\\mathcal{A}_i$ are _mutually exclusive_)\n* $\\operatorname{P}(\\mathcal{A} \\cap \\mathcal{B}) = \\operatorname{P}(\\mathcal{A} \\mid \\mathcal{B})\\operatorname{P}(\\mathcal{B})$\n* $\\operatorname{P}(\\mathcal{A} \\cap \\mathcal{B}) = \\operatorname{P}(\\mathcal{A})\\operatorname{P}(\\mathcal{B}) \\iff \\mathcal{A} \\perp \\mathcal{B}$ (eg. 2 fair dice rolls)\n* $\\mathcal{A} \\perp \\mathcal{B} \\iff \\operatorname{P}(\\mathcal{A} \\mid \\mathcal{B}) = \\operatorname{P}(\\mathcal{A})$\n\n### Random Variables {#sec-random-variables}\n\nA **random variable**  $X$ is a measurable function (mapping) $X \\colon \\mathcal{\\Omega} \\to \\mathcal{E}$ from a sample space $\\mathcal{\\Omega}$ as a set of possible outcomes to a measurable space $\\mathcal{E}$.\n\nThe probability that $X$ takes on a value in a measurable set $\\mathcal{S} \\in \\mathcal{E}$ is written as\n$$\n\\operatorname{P}(X \\in \\mathcal{S}) = \\operatorname{P}(\\{\\omega \\in \\mathcal{\\Omega} \\mid X(\\omega) \\in \\mathcal{S}\\})\n$$\n\nThe probability that $X$ takes a _discrete_ value $v$, denoted $X = v$, is $\\operatorname{P}(X=v)$.\n\nExpressions like $X = v$ or $X \\geq v$ define **events**, i.e., subsets of $\\Omega$ whose probability can be measured.\n\nRandom variables allow us to go from outcomes to values, like $X(\\omega) = \\omega$, the random variable that associates to each die its value (identity function). This is also an example of a _discrete_ random variable.\n\nWhen $X$ is _continuous_, it doesn't make sense to have events like $X = v$ (and $\\operatorname{P}(X = v) = 0$); rather we use $v \\leq X \\leq w$ and probability **densities**. An example would be the height of a population. Probabilities are described via a **probability density function** $p_X(x)$, with\n$$\n\\operatorname{P}(v \\le X \\le w) = \\int_v^w p_X(x)\\,dx\n$$\n\nWe denote the probability distribution of $X$ as $\\operatorname{P}(X)$ (strictly speaking $P_X$, but we often write $P(X)$ for convenience).\n\n:::{.callout-note}\nWhen the measurable space $\\mathcal{E}$ is multi-dimensional, like $\\mathbb{R}^m$, we call the random variable $\\mathbf{X} \\in \\mathbb{R}^m$ a **random vector**.\n:::\n\n#### Multiple Random Variables\n\n$\\operatorname{P}(A = a, B = b)$ is the **joint probability** of $A = a$ **and** $B = b$ (it's the intersection of the events $A = a$ and $B = b$). Equivalently it's $\\operatorname{P}(\\{A = a\\} \\cap \\{B = b\\})$, with an overloaded notation, the **joint probability distribution** becomes $\\operatorname{P}(A, B)$\n\nObviously $$ \\operatorname{P}(A = a, B = b) \\leq \\operatorname{P}(A=a) \\quad \\text{and} \\quad \\operatorname{P}(A = a, B = b) \\leq \\operatorname{P}(B=b) $$\n\nAlso, we can **marginalize** $$ \\operatorname{P}(A = a) = \\sum_v \\operatorname{P}(A = a, B = v) $$\n\nBecause $A = a$ and $B = b$ are events,\n$$\\begin{aligned}\n\\operatorname{P}(A = a, B = b) & = \\operatorname{P}(A = a \\mid B = b)\\operatorname{P}(B = b) \\\\\n\\iff \\operatorname{P}(A = a \\mid B = b) & = \\operatorname{P}(A = a, B = b)/\\operatorname{P}(B = b)\n\\end{aligned}$$\n\n### Bayes' Theorem\n\nFrom the properties and definitions above, we can derive the following formula\n\n$$ \\overbrace{\\operatorname{P}(A \\mid B)}^{\\text{posterior probability}} = \\dfrac{\\overbrace{\\operatorname{P}(B \\mid A)}^{\\text{likelihood}}\\overbrace{\\operatorname{P}(A)}^{\\text{prior}}}{\\underbrace{\\operatorname{P}(B)}_{\\text{observation}}} $$\n\n* prior/hypothesis: our estimate or current belief about the probability of $A$\n* observation/marginal likelihood/evidence: the evidence or observations we've made regarding $B$\n* likelihood: a measure of how compatible our hypothesis is with our observation\n\nA simplified version is $\\operatorname{P}(A \\mid B) \\propto \\operatorname{P}(B \\mid A)\\operatorname{P}(A)$\n\n### Expectation\n\nThe **expectation** (or **expected value**) is the weighted average of the values of $X$.\n\nDiscrete case:\n\n$$ \\operatorname{E}[X] = \\operatorname{E}_{X \\sim P}[X] = \\sum_x x\\operatorname{P}(X=x) $$\n\nContinuous case:\n\n$$\\operatorname{E}[X] = \\int_{-\\infty}^{\\infty} x f(x) \\;dx $$\n\nTo follow mathematical notation, sometimes we use $\\mu$ to denote this average.\n\n#### Properties\n\n<!--- TODO --->\n\n#### Expectation of a Random Vector\n\nFor a vector-valued random variable — ie. the **random vector** $\\mathbf{X} \\in \\mathbb{R}^n$, we have $\\mathbf{\\mu} = \\operatorname{E}_{\\mathbf{X} \\sim P}[\\mathbf{X}]$ with $\\mu_i = \\operatorname{E}_{\\mathbf{X} \\sim P}[x_i]$ — the expectation of $\\mathbf{X}$ is a vector of the expectations of each element $x_i$ of $\\mathbf{X}$.\n\n### Variance {#sec-variance}\n\nThe **variance** is a measure of dispersion, it quantifies _how much values deviate from their expectation, on average_.\nThe variance is the expectation of the squared difference between the values and the expected value.\n\n$$ \\operatorname{Var}(X) = \\operatorname{E}[(X - \\operatorname{E}[X])^2] = \\operatorname{E}[X^2] - (\\operatorname{E}[X])^2 $$\n\nBecause\n\n$$ \\operatorname{E}[X^2 - 2X\\operatorname{E}[X] + \\operatorname{E}[X]^2] = \\operatorname{E}[X^2] - 2(\\operatorname{E}[X])^2 + (\\operatorname{E}[X])^2 $$\n\n#### Variance of a Random Vector {#sec-var-random-vector}\n\nFor a random vector $\\mathbf{X}$, we store the pairwise **variances** of elements and **[covariances @sec-covariance]** in a **[covariance matrix @sec-covariance-matrix]** (aka. auto-covariance matrix or variance matrix) noted $\\mathbf{\\Sigma}$ or $K_{\\mathbf{x}\\mathbf{x}}$ or $\\operatorname{Cov}_{\\mathbf{x} \\sim P}$, defined as\n\n$$ \\mathbf{\\Sigma} = \\operatorname{E}_{\\mathbf{X} \\sim P}[(\\mathbf{X} - \\mathbf{\\mu})(\\mathbf{X} - \\mathbf{\\mu})^\\top] $$\n$$\\begin{aligned}\n\\mathbf{\\Sigma} = K_{\\mathbf{X}\\mathbf{Y}}\n& = \\operatorname{E}_{\\mathbf{X} \\sim P}[(\\mathbf{X} - \\mathbf{\\mu})(\\mathbf{X} - \\mathbf{\\mu})^\\top] \\\\\n& = \\operatorname{E}[\\mathbf{X}\\mathbf{X}^\\top] - \\operatorname{E}[\\mathbf{X}]\\operatorname{E}[\\mathbf{X}]^\\top\n\\end{aligned}$$\n\n:::{.callout-note}\nEach entry $\\Sigma_{i, j} = \\operatorname{Cov}(X_i, X_j)$ — see [covariance @sec-covariance]), and by definition, for diagonal entries $\\Sigma_{i, i} = \\operatorname{Cov}(X_i, X_i) = \\operatorname{Var}(X_i)$\n:::\n\n:::{.callout-note}\nWe have the following property when applying a linear transformation represented by the appropriately dimensioned matrix $\\mathbf{A}$\n\n$$\n\\begin{aligned}\n\\operatorname{Cov}(\\mathbf{AX}, \\mathbf{AX}) & = \\operatorname{E}[(\\mathbf{AX} - \\operatorname{E}[\\mathbf{AX}])(\\mathbf{AX} - \\operatorname{E}[\\mathbf{AX}])^\\top] \\\\\n& = \\operatorname{E}[\\mathbf{AX}(\\mathbf{AX})^\\top] - \\operatorname{E}[\\mathbf{AX}]\\operatorname{E}[(\\mathbf{AX})^\\top] \\\\\n& = \\operatorname{E}[\\mathbf{AX}\\mathbf{X}^\\top\\mathbf{A}^\\top] - \\operatorname{E}[\\mathbf{AX}]\\operatorname{E}[\\mathbf{X}^\\top\\mathbf{A}^\\top] \\\\\n& = \\mathbf{A}\\operatorname{E}[\\mathbf{X}\\mathbf{X}^\\top]\\mathbf{A}^\\top - \\mathbf{A}\\operatorname{E}[\\mathbf{X}]\\operatorname{E}[\\mathbf{X}^\\top]\\mathbf{A}^\\top \\\\\n& = \\mathbf{A}(\\operatorname{E}[\\mathbf{X}\\mathbf{X}^\\top] - \\operatorname{E}[\\mathbf{X}]\\operatorname{E}[\\mathbf{X}^\\top])\\mathbf{A}^\\top \\\\\n& = \\mathbf{A}\\mathbf{\\Sigma}\\mathbf{A}^\\top\n\\end{aligned}\n$$\n\n<!---TODO--->\nAs a result of the [linearity of expectation]\n:::\n\n### Standard deviation\n\nBecause the [variance @sec-variance] is a squared difference, we can take its square root to get the **standard deviation** which has the benefit of being in the same unit as our random variable.\n\n$$ \\operatorname{Var}(X) = \\sigma^2_X \\iff \\sigma_X = \\sqrt{\\operatorname{Var}(X)} $$\n\n### Covariance {#sec-covariance}\n\n**Covariance** is a measure of the joint variability of two [random variables @sec-random-variables].\n\n$$ \\operatorname{Cov}(X, Y) = \\operatorname{E}[(X - \\operatorname{E}[X])(Y - \\operatorname{E}[Y])] $$\n\n:::{.callout-note}\n$\\operatorname{Cov}(X, X) = \\operatorname{E}[(X - \\operatorname{E}[X])^2] = \\operatorname{Var}(X)$\n:::\n\n#### Covariance Matrix of two Random Vectors {#sec-covariance-matrix}\n\nFor random vectors $\\mathbf{X} \\in \\mathbb{R}^m$, $\\mathbf{Y} \\in \\mathbb{R}^n$, the **covariance matrix** is a matrix $K_{\\mathbf{X}\\mathbf{Y}}$ defined as\n\n$$\\begin{aligned}\nK_{\\mathbf{X}\\mathbf{Y}} & = \\operatorname{E}[(\\mathbf{X} - \\operatorname{E}[\\mathbf{X}])(\\mathbf{Y} - \\operatorname{E}[\\mathbf{Y}])^\\top] \\\\\n& = \\operatorname{E}[\\mathbf{X}\\mathbf{Y}^\\top] - \\operatorname{E}[\\mathbf{X}]\\operatorname{E}[\\mathbf{Y}]^\\top\n\\end{aligned}$$\n\nWe have $\\operatorname{Cov}(X_i, Y_j) = K_{X_iY_j} = \\operatorname{E}[(X_i - \\operatorname{E}[X_i])(Y_j - \\operatorname{E}[Y_j])]$ found at index $(i, j)$ in $K_{\\mathbf{X}\\mathbf{Y}}$\n\nIf $\\mathbf{X} = \\mathbf{Y}$ this is the [auto-covariance matrix or variance matrix @sec-var-random-vector] of this random vector $\\mathbf{X}$\n\nIf $\\mathbf{X} \\neq \\mathbf{Y}$ this is the **cross-covariance matrix** of $\\mathbf{X}$ and $\\mathbf{Y}$\n\n<!--- TODO: correlation, KL-Divergence --->\n\n## Proofs\n\nLater!\n\n## Notation\n\n* $\\mathcal{X}$: a set\n* $\\{a, b, c\\}$: a set, with its elements\n* $\\emptyset$: the empty set\n* $\\mathcal{A} \\subset \\mathcal{B}$, $\\mathcal{A} \\subsetneq \\mathcal{B}$: $\\mathcal{A}$ is a proper/strict subset of $\\mathcal{B}$\n* $\\mathcal{A} \\subseteq \\mathcal{B}$: $\\mathcal{A}$ is a subest of $\\mathcal{B}$\n* $\\mathcal{A} \\cap \\mathcal{B}$: the intersection of sets $\\mathcal{A}$ and $\\mathcal{B}$ — \"$\\mathcal{A}$ **and** $\\mathcal{B}$\"\n* $\\mathcal{A} \\cup \\mathcal{B}$: the union of sets $\\mathcal{A}$ and $\\mathcal{B}$ — \"$\\mathcal{A}$ **or** $\\mathcal{B}$\"\n* $\\mathcal{A} \\setminus \\mathcal{B}$: set subtraction of $\\mathcal{B}$ from $\\mathcal{A}$, elements from $\\mathcal{A}$ but not in $\\mathcal{B}$\n* $\\mathcal{S}$, $\\mathcal{\\Omega}$: the sample space / universe (the set of all possible outcomes)\n* $|\\mathcal{X}|$: the cardinality of set $\\mathcal{X}$ (its number of events)\n* $X$: a random variable\n* $\\mathbf{X}$: a random vector\n* $P$: a probability distribution\n* $X \\sim P$: the random variable $X$ follows the probability distribution $P$\n* $a \\propto b$: $a$ is proportional to $b$, eg. $a = kb$\n* $\\operatorname{P}(\\cdot)$: the probability function, maps events to their probability and random variables to their probability _distributions_\n* $\\operatorname{P}(X)$: depending on the context, a probability distribution _or_ the probability of any $X=x$, meaning the formula is true for any value\n* $\\operatorname{P}(X=x)$: the probability assigned to the event where random variable $X$ takes value $x$\n* $\\operatorname{P}(X \\mid Y)$: the conditional probability distribution of $X$ given $Y$\n* $\\operatorname{p}(\\cdot)$: a probability density function (PDF) associated with distribution $P$\n* $\\operatorname{E}[X]$: expectation of a random variable $X$\n* $X \\perp Y$: random variables $X$ and $Y$ are independent\n* $X \\perp Y \\mid Z$: random variables  $X$  and  $Y$ are conditionally independent given $Z$\n* $\\sigma_X$: standard deviation of random variable $X$\n* $\\operatorname{Var}(X)$: variance of random variable $X$, equal to $\\sigma^2_X$\n* $\\operatorname{Cov}(X, Y)$: covariance of random variables $X$ and $Y$\n* $\\operatorname{\\rho}(X, Y)$: the Pearson correlation coefficient between $X$ and $Y$, equals $\\frac{\\operatorname{Cov}(X, Y)}{\\sigma_X \\sigma_Y}$\n* $\\operatorname{H}(X)$: entropy of random variable $X$\n* $D_{\\operatorname{KL}}(P\\|Q)$: the KL-divergence (or relative entropy) from distribution $Q$ to distribution $P$\n\n",
    "supporting": [
      "probability_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}