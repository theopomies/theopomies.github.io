{
  "hash": "343e300850b9826ec12037bf0057fe4a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Probability and Information Theory\nauthor: Theo POMIES\ndate: 2025-09-02\ndate-modified: 2025-09-04\ndescription: Small Probability & Information Theory cheatsheet.\ncategories: [math]\n---\n\n\n\n## Definitions & Formulas\n### Outcomes and Events\nWhen studying probability, we are performing experiments, random trials or observations. The set of all possible _outcomes_ of this experiment is $\\mathcal{\\Omega}$ (or $\\mathcal{S}$). eg. When rolling a die, $\\mathcal{\\Omega} = \\{1,2,3,4,5,6\\}$.\n\nWe can group these outcomes into _events_ — $\\mathcal{E} \\subseteq \\mathcal{\\Omega}$. eg. The event $\\mathcal{E} = \\{die shows an even number\\} = \\{2, 4, 6\\}$. Whenever the outcome $z$ of the random experiment satisfies $z \\in \\mathcal{E}$, the event $\\mathcal{E}$ has occurred. Multiple events can occur from the same outcome, say we have $\\mathcal{A} = \\{3, 6\\}$ \"the result is divisible by 3\" and $\\mathcal{B} = \\{2, 4, 6\\}$. $z = 6$ satisfies both $\\mathcal{A}$ and $\\mathcal{B}$.\n\n### Probability function\n\nThe **probability function** maps events onto a real value $P\\colon \\mathcal{E} \\subseteq \\mathcal{\\Omega} \\to [0, 1]$.\n\n$\\operatorname{P}(\\mathcal{E})$ is the _probability associated with event $\\mathcal{E}$_.\n\n#### Properties\n\n* $\\operatorname{P}(\\mathcal{E}) \\geq 0$\n* $\\operatorname{P}(\\mathcal{\\Omega}) = 1, \\operatorname{P}(\\mathcal{\\emptyset}) = 0$\n* $\\operatorname{P}(\\mathcal{A} \\cup \\mathcal{B}) = \\operatorname{P}(\\mathcal{A}) + \\operatorname{P}(\\mathcal{B}) - \\operatorname{P}(\\mathcal{A} \\cap \\mathcal{B})$\n* $\\operatorname{P}(\\bigcup_{i=1}^{\\infty} \\mathcal{A}_i) = \\sum_{i=1}^{\\infty} \\operatorname{P}(\\mathcal{A}_i), \\quad \\mathcal{A}_i \\cap \\mathcal{A}_j = \\emptyset\\: \\text{for all}\\: i \\neq j$ (= if all events $\\mathcal{A}_i$ are _mutually exclusive_)\n* $\\operatorname{P}(\\mathcal{A} \\cap \\mathcal{B}) = \\operatorname{P}(\\mathcal{A} \\mid \\mathcal{B})\\operatorname{P}(\\mathcal{B})$\n* $\\operatorname{P}(\\mathcal{A} \\cap \\mathcal{B}) = \\operatorname{P}(\\mathcal{A})\\operatorname{P}(\\mathcal{B}) \\iff \\mathcal{A} \\perp \\mathcal{B}$ (eg. 2 fair dice rolls)\n* $\\mathcal{A} \\perp \\mathcal{B} \\iff \\operatorname{P}(\\mathcal{A} \\mid \\mathcal{B}) = \\operatorname{P}(\\mathcal{A})$\n\n### Random Variables\n\nA **random variable**  $X$ is a measurable function (mapping) $X \\colon \\mathcal{\\Omega} \\to \\mathcal{E}$ from a sample space $\\mathcal{\\Omega}$ as a set of possible outcomes to a measurable space $\\mathcal{E}$.\n\nThe probability that $X$ takes on a value in a measurable set $\\mathcal{S} \\in \\mathcal{E}$ is written as $\\operatorname{P}(X \\in \\mathcal{S}) = \\operatorname{P}(\\{\\omega \\in \\mathcal{\\Omega} \\mid X(\\omega) \\in \\mathcal{S}\\})$\n\nThe probability that $X$ takes _discrete_ value $v$, denoted $X = v$, is $\\operatorname{P}(X=v)$.\n\n$X = v$ or $X \\geq v$ are **events**.\n\nRandom variables allow us to go from outcomes to values, like $X(\\omega) = \\omega$ the random variable that associates to each die its value (identity function). This is also an example of a _discrete_ random variable.\n\nWhen $X$ is _continuous_ it doesn't make sense to have events like $X = v$ (and $\\operatorname{P}(X = v) = 0$), rather we use $v \\leq X \\leq w$ and probability **densities**. An example would be the height of a population.\n\nWe note $\\operatorname{P}(X)$ the **probability distribution** of X. (Abuse of notation: strictly $P_X$ is the distribution of $X$, but we’ll often just write $P(X)$)\n\n#### Multiple Random Variables\n\n$\\operatorname{P}(A = a, B = b)$ is the **joint probability** of $A = a$ **and** $B = b$ (it's the intersection of the events $A = a$ and $B = b$). Equivalently it's $\\operatorname{P}(\\{A = a\\} \\cap \\{B = b\\})$, with an overloaded notation, the **joint probability distribution** becomes $\\operatorname{P}(A, B)$\n\nObviously $$ \\operatorname{P}(A = a, B = b) \\leq \\operatorname{P}(A=a) \\quad \\text{and} \\quad \\operatorname{P}(A = a, B = b) \\leq \\operatorname{P}(B=b) $$\n\nAlso, we can **marginalize** $$ \\operatorname{P}(A = a) = \\sum_v \\operatorname{P}(A = a, B = v) $$\n\nBecause $A = a$ and $B = b$ are events,\n$$\\begin{aligned}\n\\operatorname{P}(A = a, B = b) & = \\operatorname{P}(A = a \\mid B = b)\\operatorname{P}(B = b) \\\\\n\\iff \\operatorname{P}(A = a \\mid B = b) & = \\operatorname{P}(A = a, B = b)/\\operatorname{P}(B = b)\n\\end{aligned}$$\n\n### Bayes' Theorem\n\nFrom the properties and definitions above, we can derive the following formula\n\n$$ \\overbrace{\\operatorname{P}(A \\mid B)}^{\\text{posterior probability}} = \\dfrac{\\overbrace{\\operatorname{P}(B \\mid A)}^{\\text{likelihood}}\\overbrace{\\operatorname{P}(A)}^{\\text{prior}}}{\\underbrace{\\operatorname{P}(B)}_{\\text{observation}}} $$\n\n* prior/hypothesis: our estimate or current belief about the probability of $A$\n* observation/marginal likelihood/evidence: the evidence or observations we've made regarding $B$\n* likelihood: a measure of how compatible our hypothesis is with our observation\n\nA simplified version is $\\operatorname{P}(A \\mid B) \\propto \\operatorname{P}(B \\mid A)\\operatorname{P}(A)$\n\n### Expectation & Variance\n#### Expectation\n\nThe **expectation** (or **expected value**) is the weighted average of the values of $X$.\n\nDiscrete case:\n\n$$ \\operatorname{E}[X] = \\operatorname{E}_{x \\sim P}[X] = \\sum_x x\\operatorname{P}(X=x) $$\n\nContinuous case:\n\n$$\\operatorname{E}[X] = \\int_{-\\infty}^{\\infty} x f(x) \\;dx $$\n\nTo follow mathematical notation, sometimes we use $\\mu$ to denote this average.\n\n#### Variance\n\nThe **variance** is a measure of dispersion, it quantifies _how much do values vary relative to the expectation (average) on average_.\nThe variance is the expectation of the squared difference between the values and the expected value.\n\n$$ \\operatorname{Var}(X) = \\operatorname{E}[(X - \\operatorname{E}[X])^2] = \\operatorname{E}[X^2] - (\\operatorname{E}[X])^2 $$\n\nBecause\n\n$$ \\operatorname{E}[X^2 - 2X\\operatorname{E}[X] + \\operatorname{E}[X]^2] = \\operatorname{E}[X^2] - 2(\\operatorname{E}[X])^2 + (\\operatorname{E}[X])^2 $$\n\n#### Standard deviation\n\nBecause the variance is a squared difference, we can take its square root to get the **standard deviation** which has the benefit of being in the same unit as our random variable.\n\n$$ \\operatorname{Var}(X) = \\sigma^2_X \\iff \\sigma_X = \\sqrt{\\operatorname{Var}(X)} $$\n\n#### Covariance\n\nTODO once I understand it fully enough to explain it.\n\n## Notes\n\n## Proofs\n\nLater!\n\n## Algorithms\n\n## Notation\n\n* $\\mathcal{X}$: a set\n* $\\{a, b, c\\}$: a set, with its elements\n* $\\emptyset$: the empty set\n* $\\mathcal{A} \\subset \\mathcal{B}$, $\\mathcal{A} \\subsetneq \\mathcal{B}$: $\\mathcal{A}$ is a proper/strict subset of $\\mathcal{B}$\n* $\\mathcal{A} \\subseteq \\mathcal{B}$: $\\mathcal{A}$ is a subest of $\\mathcal{B}$\n* $\\mathcal{A} \\cap \\mathcal{B}$: the intersection of sets $\\mathcal{A}$ and $\\mathcal{B}$ — \"$\\mathcal{A}$ **and** $\\mathcal{B}$\"\n* $\\mathcal{A} \\cup \\mathcal{B}$: the union of sets $\\mathcal{A}$ and $\\mathcal{B}$ — \"$\\mathcal{A}$ **or** $\\mathcal{B}$\"\n* $\\mathcal{A} \\setminus \\mathcal{B}$: set subtraction of $\\mathcal{B}$ from $\\mathcal{A}$, elements from $\\mathcal{A}$ but not in $\\mathcal{B}$\n* $\\mathcal{S}$, $\\mathcal{\\Omega}$: the sample space / universe (the set of all possible outcomes)\n* $|\\mathcal{X}|$: the cardinality of set $\\mathcal{X}$ (its number of events)\n* $X$: a random variable\n* $P$: a probability distribution\n* $X \\sim P$: the random variable $X$ follows the probability distribution $P$\n* $a \\propto b$: $a$ is proportional to $b$, eg. $a = kb$\n* $\\operatorname{P}(\\cdot)$: the probability function, maps events to their probability and random variables to their probability _distributions_\n* $\\operatorname{P}(X)$: depending on the context, a probability distribution _or_ the probability of any $X=x$, meaning the formula is true for any value\n* $\\operatorname{P}(X=x)$: the probability assigned to the event where random variable $X$ takes value $x$\n* $\\operatorname{P}(X \\mid Y)$: the conditional probability distribution of $X$ given $Y$\n* $\\operatorname{p}(\\cdot)$: a probability density function (PDF) associated with distribution $P$\n* $\\operatorname{E}[X]$: expectation of a random variable $X$\n* $X \\perp Y$: random variables $X$ and $Y$ are independent\n* $X \\perp Y \\mid Z$: random variables  $X$  and  $Y$ are conditionally independent given $Z$\n* $\\sigma_X$: standard deviation of random variable $X$\n* $\\textrm{Var}(X)$: variance of random variable $X$, equal to $\\sigma^2_X$\n* $\\textrm{Cov}(X, Y)$: covariance of random variables $X$ and $Y$\n* $\\operatorname{\\rho}(X, Y)$: the Pearson correlation coefficient between $X$ and $Y$, equals $\\frac{\\textrm{Cov}(X, Y)}{\\sigma_X \\sigma_Y}$\n* $\\operatorname{H}(X)$: entropy of random variable $X$\n* $D_{\\textrm{KL}}(P\\|Q)$: the KL-divergence (or relative entropy) from distribution $Q$ to distribution $P$\n\n",
    "supporting": [
      "probability_files"
    ],
    "filters": [],
    "includes": {}
  }
}